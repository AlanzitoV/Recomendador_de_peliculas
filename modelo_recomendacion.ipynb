{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267f5ad7-4dd7-412b-8c5f-be13d2913238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9340ee08-13d8-42ad-b14e-83d7d12bef71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'df_modificado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dca8d8-2578-4d25-94eb-2caf4deaffdb",
   "metadata": {},
   "source": [
    "decido hacer el sistema de recomendacion con las columnas que poseen texto por lo que elimino las columnas numericas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92abfe76-90c9-4f83-993b-99751f8d819c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(['crew', 'popularity','runtime','vote_average','vote_count'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55842631-518b-47d5-bac5-19b6540cdbfd",
   "metadata": {},
   "source": [
    "De la columna cast tomo los primeros 3 actores y aplico modificaciones para quitar corchetes y comillas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1542ec-f2f9-4b34-97b0-03702b910458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['cast'] = df['cast'].apply(lambda x: x.split(\",\")[:3] if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b33c830-b9f2-434e-b721-4abfd53a252b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['cast'] = df['cast'].astype(str).str.replace('[', '').str.replace(']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2165fd1c-d662-4ae6-a6b3-cc879806d99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['cast'] = df['cast'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7dc7f3e-78d7-4c1d-981e-221c603b5204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom Hanks,  Tim Allen,  Don Rickles\n"
     ]
    }
   ],
   "source": [
    "primer_registro = df['cast'].iloc[0]\n",
    "print(primer_registro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e0095-dbf8-4bea-83e6-9ca6764e0827",
   "metadata": {},
   "source": [
    "Creo una columna donde se convinen todas las palabras de la lista de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d046e3b2-d570-4fc7-8d54-2776be81131c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columnas_convinadas = ['genres','overview']\n",
    "df['texto_combinado'] = df[columnas_convinadas].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1848e3c9-7260-4e95-8e79-8da87e09e6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animation, Comedy, Family Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\n"
     ]
    }
   ],
   "source": [
    "celda_completa = df.loc[0, 'texto_combinado']\n",
    "print(celda_completa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f98a3-7aa6-49f8-83de-3c7015417dc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "aplico la tokenizacion, elimino los stop_words y lemmatizo el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14040d40-bb3e-4716-b775-8699c8d05270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['texto_conbinado_tokenizado'] = df['texto_combinado'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20b2c2e1-db2a-4acf-81e9-3482b23d1947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df['texto_conbinado_sin_stopwords'] = df['texto_conbinado_tokenizado'].apply(lambda x: [word for word in x if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b42fb2af-7b27-4afb-85a5-7bc2ab887339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['texto_lemmatizado'] = df['texto_conbinado_sin_stopwords'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba974e59-0b8d-4f5d-be62-8f49df90efb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Animation', ',', 'Comedy', ',', 'Family', 'Led', 'Woody', ',', 'Andy', \"'s\", 'toy', 'live', 'happily', 'room', 'Andy', \"'s\", 'birthday', 'brings', 'Buzz', 'Lightyear', 'onto', 'scene', '.', 'Afraid', 'losing', 'place', 'Andy', \"'s\", 'heart', ',', 'Woody', 'plot', 'Buzz', '.', 'circumstance', 'separate', 'Buzz', 'Woody', 'owner', ',', 'duo', 'eventually', 'learns', 'put', 'aside', 'difference', '.']\n"
     ]
    }
   ],
   "source": [
    "celda_completa = df.loc[0, 'texto_lemmatizado']\n",
    "print(celda_completa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c9fae0-5d46-483f-af1e-28fe2908e32c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Se crea el modelo utilizando la tecnica de Bolsa de Palabras y la similitud del coseno para encontrar similitudes entre los textos lematizados. Se guarda el modelo en un archivo utilizando joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33454a91-6daf-4211-a160-fc8c2558d456",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_joblib.joblib']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crear_modelo_recomendacion(df):\n",
    "    texto_lemmatizado = [' '.join(tokens) for tokens in df['texto_lemmatizado']]\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    matriz_tdm = vectorizer.fit_transform(texto_lemmatizado).astype(np.float32)\n",
    "\n",
    "    vocabulario = vectorizer.get_feature_names_out()\n",
    "\n",
    "    similarity_matrix = cosine_similarity(matriz_tdm)\n",
    "\n",
    "    modelo_recomendacion = {\n",
    "        'df': df,\n",
    "        'vectorizer': vectorizer,\n",
    "        'similarity_matrix': similarity_matrix\n",
    "    }\n",
    "\n",
    "    return modelo_recomendacion\n",
    "\n",
    "\n",
    "modelo_recomendacion = crear_modelo_recomendacion(df)\n",
    "\n",
    "joblib.dump(modelo_recomendacion, 'modelo_joblib.joblib')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fa065f1-12d8-4b69-a916-25f8d85cc3e9",
   "metadata": {},
   "source": [
    "Guardamos la columna lemmatizada en el df_modificado para poder usar el mismo df para las consultas y las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7de1559a-c566-49ba-9976-6b3cc1b79659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['title', 'texto_lemmatizado']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2043884-77cc-4253-bda0-13ec7684bf3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r'df_modificado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3127cfd-55df-425c-aaa3-775568d96cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, df2, on='title')\n",
    "df = df.head(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ab91881-1cda-4495-b92b-5bc40de85c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(r'df_modificado.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ccc89-1405-4788-8c4f-18c08e4d8ed4",
   "metadata": {},
   "source": [
    "El archivo con el modelo entrenado pesa 7GB por lo que procedo a reducir el DataFrame para cumplir con los requisitos de almacenamiento en github (2gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec0a9ddf-1e12-417f-b797-ecd5ee47962b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   title                 3000 non-null   object \n",
      " 1   texto_lemmatizado     3000 non-null   object \n",
      " 2   genres                2791 non-null   object \n",
      " 3   overview              2999 non-null   object \n",
      " 4   popularity            3000 non-null   float64\n",
      " 5   production_companies  2416 non-null   object \n",
      " 6   runtime               3000 non-null   float64\n",
      " 7   tagline               1654 non-null   object \n",
      " 8   vote_average          3000 non-null   float64\n",
      " 9   vote_count            3000 non-null   float64\n",
      " 10  cast                  2929 non-null   object \n",
      " 11  crew                  2992 non-null   object \n",
      "dtypes: float64(4), object(8)\n",
      "memory usage: 281.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8262eaa6-dde3-4407-9be1-4c0058d3df56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.head(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "301cfdff-5a4a-4463-a6bb-99ed61c7b5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(['texto_lemmatizado_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da81c05e-bc53-408d-a219-9123cece7138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'texto_lemmatizado_x': 'texto_lemmatizado'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98479578-679c-443e-af09-9e08549f8726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(['texto_combinado', 'texto_conbinado_tokenizado', 'texto_conbinado_sin_stopwords'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11215cc-d810-491a-ba17-57ca7e7638e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'df_modificado.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
